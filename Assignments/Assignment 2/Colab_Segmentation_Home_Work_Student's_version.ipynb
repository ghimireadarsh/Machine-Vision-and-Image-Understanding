{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab Segmentation_Home_Work_Student's_version.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBABConrhpzH"
      },
      "source": [
        "## **1. Colab GPU configuration**\n",
        "\n",
        "In Colab, you have 12 hours, however if you remain inactive for over 60 minutes, the session is unplugged. It indicates that the disk, RAM, CPU and data on the assigned virtual device would be deleted every 12 hours.\n",
        "\n",
        "To enable GPU hardware accelerator, just go to **Runtime -> Change runtime type -> Hardware accelerator -> GPU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPosxiwLS7iR"
      },
      "source": [
        "## **2. Requirements**\n",
        "\n",
        "This notebook requires the following libraries, \n",
        "torch, torchvision, scikit-image, numpy, glob, tqdm, random, itertools, matplotlib. \n",
        "\n",
        "You can install them in Colab using **pip** like: \n",
        "\n",
        "!pip install torch torchvision\n",
        "\n",
        "You can install all other needed packages using the methodology."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH-5SfovzEug"
      },
      "source": [
        "!pip install torch torchvision scikit-image numpy glob2 tqdm matplotlib tifffile imagecodecs "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o5cg-qyVkWm"
      },
      "source": [
        "## **3. Mount google drive**\n",
        "\n",
        "**3.1.** This example (UNet model) is trained on the ISPRS Potsdam dataset. We use the IRRG tiles (8bit format). Make sure that the Potsdam data is in your google drive:\n",
        "/content/gdrive/patches\n",
        "\n",
        "\n",
        "**3.2.** Mount your google drive \n",
        "Google colab needs your authorization. To do that, follow the link that should be shown when running drive.mount, and enter your authorization code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpGsg97g606A"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL8-cYHCY9Tt"
      },
      "source": [
        "##**4. Import the necessary packages:**\n",
        "numpy, io, glob, tqdm_notebook, confusion_matrix, random, itertools, matplotlib.pyplot, torch, torch.nn,  torch.nn.functional, torch.utils.data, torch.optim, torch.optim.lr_scheduler, torch.nn.init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tKpIYdKZFpL"
      },
      "source": [
        "import numpy as np\n",
        "from skimage import io\n",
        "from glob import glob\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import random\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "# Torch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler\n",
        "import torch.nn.init\n",
        "from torch.autograd import Variable\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "import tifffile as tiff "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cm8u6dl-w7F"
      },
      "source": [
        "## **5. Initialization:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcCU5ZRO-xko"
      },
      "source": [
        "# Parameters\n",
        "IN_CHANNELS =  3                          # Number of input channels (e.g. RGB)\n",
        "MAIN_FOLDER  =    \"/content/gdrive/My Drive/patches/\"   # Replace with your \"/path/to/the/Images/folder/\"\n",
        "BATCH_SIZE =   10            # Number of samples in a mini-batch, example 10\n",
        "LABELS = [\"roads\", \"buildings\", \"low veg.\", \"trees\", \"cars\", \"clutter\"] # Label names\n",
        "N_CLASSES = len(LABELS)                   # Number of classes\n",
        "weights = torch.ones(N_CLASSES)           # Weights for class balancing\n",
        "DATA_FOLDER = MAIN_FOLDER + 'Images/Image_{}.tif'\n",
        "LABELS_FOLDER = MAIN_FOLDER + 'Labels/Label_{}.tif'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stD67gExSJhx"
      },
      "source": [
        "## **6. Functions you may need:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXOGgStBqKta"
      },
      "source": [
        "# Let's define the standard ISPRS color palette\n",
        "palette = {0 : (255, 255, 255), # Impervious surfaces (white)\n",
        "           1 : (0, 0, 255),     # Buildings (blue)\n",
        "           2 : (0, 255, 255),   # Low vegetation (cyan)\n",
        "           3 : (0, 255, 0),     # Trees (green)\n",
        "           4 : (255, 255, 0),   # Cars (yellow)\n",
        "           5 : (255, 0, 0),     # Clutter (red)\n",
        "           6 : (0, 0, 0)}       # Undefined (black)\n",
        "invert_palette = {v: k for k, v in palette.items()}\n",
        "def convert_from_color(arr_3d, palette=invert_palette):\n",
        "    \"\"\" RGB-color encoding to grayscale labels \"\"\" '(From 0 to 6)'\n",
        "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)\n",
        "    for c, i in palette.items():\n",
        "        m = np.all(arr_3d == np.array(c).reshape(1, 1, 3), axis=2)\n",
        "        arr_2d[m] = i\n",
        "    return arr_2d\n",
        "class Load_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, ids):\n",
        "        super(Load_dataset, self).__init__()\n",
        "        # List of files\n",
        "        self.data_files = [DATA_FOLDER.format(id) for id in ids]\n",
        "        self.label_files = [LABELS_FOLDER.format(id) for id in ids]\n",
        "        # Sanity check : raise an error if some files do not exist\n",
        "        for f in self.data_files + self.label_files:\n",
        "            if not os.path.isfile(f):\n",
        "                raise KeyError('{} is not a file !'.format(f))\n",
        "    def __len__(self):\n",
        "        return len(self.data_files) # the length of the used data\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "#         Pre-processing steps\n",
        "        #     # Data is normalized in [0, 1]\n",
        "        self.data = 1/255 * np.asarray(io.imread(self.data_files[idx]).transpose((2,0,1)), dtype='float32')\n",
        "        self.label = np.asarray(convert_from_color(io.imread(self.label_files[idx])), dtype='int64')\n",
        "        data_p, label_p = self.data,  self.label\n",
        "        # Return the torch.Tensor values\n",
        "        return (torch.from_numpy(data_p),\n",
        "                torch.from_numpy(label_p))\n",
        "def CrossEntropy2d(input, target, weight=None, size_average=True):\n",
        "    \"\"\" 2D version of the cross entropy loss \"\"\"\n",
        "    dim = input.dim()\n",
        "    if dim == 2:\n",
        "        return F.cross_entropy(input, target, weight, size_average)\n",
        "    elif dim == 4:\n",
        "        output = input.view(input.size(0), input.size(1), -1)\n",
        "        output = torch.transpose(output, 1, 2).contiguous()\n",
        "        output = output.view(-1, output.size(2))\n",
        "        target = target.view(-1)\n",
        "        return F.cross_entropy(output, target, weight, size_average)\n",
        "    else:\n",
        "        raise ValueError('Expected 2 or 4 dimensions (got {})'.format(dim))\n",
        "        \n",
        "def metrics(predictions, gts, label_values=LABELS):\n",
        "    cm = confusion_matrix(\n",
        "        gts,\n",
        "        predictions,\n",
        "        range(len(label_values)))\n",
        "    print(\"Confusion matrix :\")\n",
        "    print(cm)\n",
        "    print(\"---\")\n",
        "    # Compute global accuracy\n",
        "    total = sum(sum(cm))\n",
        "    accuracy = sum([cm[x][x] for x in range(len(cm))])\n",
        "    accuracy *= 100 / float(total)\n",
        "    print(\"{} pixels processed\".format(total))\n",
        "    print(\"Total accuracy : {}%\".format(accuracy))\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8b0JrxlHwa6"
      },
      "source": [
        "# **7. Selecting training and testing data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDy_sgh8GLRu"
      },
      "source": [
        "train_ids =list(range(0, 2000))\n",
        "test_ids =  list(range(2000,2400))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxUw_fJCfDIj"
      },
      "source": [
        "## **8. Implement the Unet model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqkolC2TfTiN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ilf1VptaihEb"
      },
      "source": [
        "# **9. Training:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzXM-oj6fUKr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATW5NLVqggLa"
      },
      "source": [
        "## **10.Testing:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0x-onidfUuj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}