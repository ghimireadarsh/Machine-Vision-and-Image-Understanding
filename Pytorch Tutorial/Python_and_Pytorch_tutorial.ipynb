{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python and Pytorch tutorial.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIG_YwwJUrqN"
      },
      "source": [
        "x= 3\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GHo0umblWB5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsRjm7XiU0R3"
      },
      "source": [
        "A='Hello Mam, he said'\n",
        "print(A)\n",
        "A=\"Hello Mam, he said\"\n",
        "print(A)\n",
        "A='\"Hello Mam\", he said'\n",
        "print(A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNS2nRgkXSAT"
      },
      "source": [
        "def Recursion(k):\n",
        "  if(k > 0):\n",
        "    result = k + tri_recursion(k - 1)\n",
        "    print(result)\n",
        "  else:\n",
        "    result = 0\n",
        "  return result\n",
        "\n",
        "print(\"Recursion Example Results\")\n",
        "Recursion(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ght8YRsilgNA"
      },
      "source": [
        "Ar1=[2, 3, 5, 2, 11, 2, 7]\n",
        "Ar2=[1, 4, 2]\n",
        "x= [10, 7, 2, 5, 2, 11]\n",
        "Ar2.append(x)\n",
        "print(Ar2)\n",
        "Ar1.extend(x)\n",
        "print(Ar1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn6qlblqYnMj"
      },
      "source": [
        "Ar1=[2, 3, 5, 2, 11, 2, 7]\n",
        "Ar2=[1, 4, 2]\n",
        "x= [10, 7, 2, 5, 2, 11]\n",
        "Ar2.append(x)\n",
        "print(Ar2)\n",
        "Ar1.extend(x)\n",
        "print(Ar1)\n",
        "count = Ar1.count(2)\n",
        "print('Count of 2:', count)\n",
        "index = Ar1.index(2)\n",
        "print(index)\n",
        "Ar1.sort()\n",
        "print(Ar1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC4UUvmreUrm"
      },
      "source": [
        "a= [[1., -1.], [1., -1.]]\n",
        "print(a)\n",
        "import torch\n",
        "a_torch= torch.tensor(a, dtype=torch.float64)\n",
        "print(a_torch, a_torch.dtype)\n",
        "import numpy as np\n",
        "a_np=np.array(a); print(a_np)\n",
        "a_torch= torch.from_numpy(a_np)\n",
        "print(a_torch, a_torch.dtype)\n",
        "a_np=a_torch.numpy()\n",
        "print(a_np)\n",
        "a_rand  =torch.rand((2,2))\n",
        "print(a_rand)\n",
        "a_ones  =torch.ones((2,2))\n",
        "print(a_ones)\n",
        "a_zeros  =torch.zeros((2,2))\n",
        "print(a_zeros)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry2UD-tIgQJI"
      },
      "source": [
        "import autograd.numpy as au  # Thinly-wrapped numpy\n",
        "from autograd import grad    # The only autograd function you may ever need\n",
        "def exp_reducerNP(x):   \n",
        "  # Define a function\n",
        "  y = au.exp(-2.0 * x)\n",
        "  return y  #\n",
        "grad_tanh = grad(exp_reducerNP)       # Obtain its gradient function\n",
        "g= grad_tanh(1.0)                     # Evaluate the gradient at x = 1.0\n",
        "c=(exp_reducerNP(1.0001) - exp_reducerNP(0.9999)) / 0.0002  # Compare to finite differences\n",
        "\n",
        "# Torch version\n",
        "import torch\n",
        "def exp_reducer(x):\n",
        "   y=-2.0*x \n",
        "   return y.exp() \n",
        "a_torch = torch.tensor(1.0)\n",
        "c_torch=torch.autograd.functional.jacobian(exp_reducer, a_torch)\n",
        "print(g, c, c_torch) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj3eEdz7JSfZ"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "488q6s2Qev15"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh3fwOW5QdDV"
      },
      "source": [
        "img, target = trainset[0],trainset[1]\n",
        "np.array(img[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FOen0fVdnDY"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ExampleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = ExampleNN()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQLiUussiswr"
      },
      "source": [
        "NN_example= ExampleNN()\n",
        "input_ex=torch.rand(1,3,32,32)\n",
        "input_ex = (input_ex-torch.mean(input_ex))/torch.std(input_ex)\n",
        "out=NN_example(input_ex)\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSaXbiWqlWXd"
      },
      "source": [
        "NN_example.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j269B0YroVi"
      },
      "source": [
        "print(labels[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoBeyf8Fm9k_"
      },
      "source": [
        "target = torch.empty(1, dtype=torch.long).random_(5)\n",
        "NN_example= ExampleNN()\n",
        "input_ex=torch.rand(1,3,32,32)\n",
        "input_ex = (input_ex-torch.mean(input_ex))/torch.std(input_ex)\n",
        "out=NN_example(input_ex)\n",
        "loss_function = nn.CrossEntropyLoss()     # nn.MSELoss()   for regrission problem\n",
        "                                          # nn.CrossEntropyLoss()   for classification problem\n",
        "loss = loss_function(out, target)\n",
        "print(loss, target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXQIjKk_oqNA"
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ag2eMYApf6J"
      },
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G0MA16QuNvj"
      },
      "source": [
        "for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENPGdGxd0hKA"
      },
      "source": [
        "### **USING CPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4t8R1p6u9nk"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "class ExampleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x=F.relu(self.conv1(x))\n",
        "        # print(x.shape)\n",
        "        x = self.pool(x)\n",
        "        # print(x.shape)\n",
        "        x= F.relu(self.conv2(x))\n",
        "        # print(x.shape)\n",
        "        x = self.pool(x)\n",
        "        # print(x.shape)\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = ExampleNN()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 200))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4n5TnCbyOZ2"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkBXy5sM0ynX"
      },
      "source": [
        "### **USING GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVpZgshy01Qv"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "class ExampleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = ExampleNN()\n",
        "########################\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net.to(device)\n",
        "from torchsummary import summary\n",
        "summary(net,(3, 256, 256))\n",
        "#######################\n",
        "#optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "optimizer =  optim.Adam([{'params': net.fc2.parameters(), 'lr': 1e-3}, {'params': net.fc3.parameters(), 'lr': 1e-1}], betas=(0.9, 0.999), lr=1e-2)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        \n",
        "        #   To GPU\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 200))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFMki3Xx1fLg"
      },
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "###GPU\n",
        "start_time = time.time()\n",
        "b = torch.ones(4000,4000).cuda()\n",
        "for _ in range(100):\n",
        "    b += b\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "print('GPU time = ',elapsed_time)\n",
        "\n",
        "###CPU\n",
        "start_time = time.time()\n",
        "a = torch.ones(4000,4000)\n",
        "for _ in range(100):\n",
        "    a += a\n",
        "elapsed_time = time.time() - start_time\n",
        "\n",
        "print('CPU time = ',elapsed_time)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PonpgFp3IHy"
      },
      "source": [
        "def EndOfLecture(statment):\n",
        "  return statment\n",
        "statment = 'Tank you for your listening'\n",
        "print(EndOfLecture(statment))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}